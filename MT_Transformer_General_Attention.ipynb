{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zH0K5vGVlY2"
      },
      "source": [
        "# Machine Translation + Transformer\n",
        "\n",
        "<img src = \"../figures/transformer1.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchdata\n",
        "# !pip install torch==2.2.0 torchtext==0.17.0\n",
        "# !pip install datasets\n",
        "# !pip install pyidaungsu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z-XorRi_V0qN"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtELAKwuZu7I",
        "outputId": "244808ec-c4f7-4bfc-eda1-f0b65664ce48"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 'models' directory if it doesn't exist\n",
        "import os\n",
        "models_dir = \"/content/drive/MyDrive/models\"  # Replace with your desired path\n",
        "os.makedirs(models_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Rg3U81vEZ_qC"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1achhdMOVlY4",
        "outputId": "46b270e8-4419-42cd-fc01-15cf03e64839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "vicj79XSVlY7"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WggQSyw1VlY8",
        "outputId": "33cb9e6c-fdba-497f-eafc-96b591f080ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 235
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9XZX5y12VlY9",
        "outputId": "05972855-a9f3-4c19-bfb4-8a9b3933d2b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.17.0+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 236
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "IACCellNVlY-"
      },
      "source": [
        "## 1. ETL: Loading the dataset\n",
        "\n",
        "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "import pyidaungsu"
      ],
      "metadata": {
        "id": "NgYgL7qzk50Q"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(\"myamjechal/en_my_myanmar-xnli_small\")"
      ],
      "metadata": {
        "id": "OgOpgUmlJXKH"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch only 20,000 rows for train dataset due to execution time\n",
        "train_dataset = [(row['en'], row['my']) for row in dataset['train']][:15000]\n",
        "val_dataset = [(row['en'], row['my']) for row in dataset['validation']]\n",
        "test_dataset = [(row['en'], row['my']) for row in dataset['test']]"
      ],
      "metadata": {
        "id": "nZrEygAAl2jI"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1cyGTdbu4Dz",
        "outputId": "886b848b-d66e-4fe6-9a74-d27064f3f178"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "-pbb8qLfVlY_"
      },
      "source": [
        "## 2. EDA - simple investigation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = [row for row in train_dataset if row[0] is not None and row[1] is not None]\n",
        "val_dataset = [row for row in val_dataset if row[0] is not None and row[1] is not None]\n",
        "test_dataset = [row for row in test_dataset if row[0] is not None and row[1] is not None]"
      ],
      "metadata": {
        "id": "zz_7V_qZLfGI"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's take a look at one example of train\n",
        "sample = next(iter(train_dataset))\n",
        "sample"
      ],
      "metadata": {
        "id": "ZbsdSNOiVuzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d5cfa2-a112-491d-cc9f-20e957814f52"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqiBkYqbVlZA",
        "outputId": "fef314dd-3287-4f38-afe4-1536ce7b61eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14978"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ],
      "source": [
        "train_size = len(list(iter(train_dataset)))\n",
        "train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfuvGwXIVlZB",
        "outputId": "5f09cdbc-78eb-46cf-82d9-947b9c0501fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2490"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ],
      "source": [
        "val_size = len(list(iter(val_dataset)))\n",
        "val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_g-UifpVlZB",
        "outputId": "384af713-7837-4a14-88fa-b7d7a62fa75a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5010"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ],
      "source": [
        "test_size = len(list(iter(test_dataset)))\n",
        "test_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "YQRI054OVlZB"
      },
      "source": [
        "## 3. Preprocessing\n",
        "\n",
        "### Tokenizing\n",
        "\n",
        "**Note**: the models must first be downloaded using the following on the command line:\n",
        "```\n",
        "python3 -m spacy download en_core_web_sm\n",
        "python3 -m spacy download de_core_news_sm\n",
        "```\n",
        "\n",
        "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JkEhOy8Pb0qi"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "Kc-yzoDVVlZC"
      },
      "outputs": [],
      "source": [
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'my'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_tokenizer(text):\n",
        "  return pyidaungsu.tokenize(text, form='word')"
      ],
      "metadata": {
        "id": "KMbboChFa9GF"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In2raKhWVlZC",
        "outputId": "c721fab6-0777-41dd-f18a-f2267b025956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TRG_LANGUAGE] = my_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx97Q3TEbKQv",
        "outputId": "18a38d00-917c-43a4-f26b-1b52cdb84667"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDWy-On8VlZC",
        "outputId": "289b5efc-12b0-44a9-ec89-d4ab0cbfb240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  ရပါတယ်။\n",
            "Tokenization:  ['ရပါတယ်။']\n"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the english part\n",
        "print(\"Sentence: \", sample[1])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsgLYX8tVlZC"
      },
      "source": [
        "A function to tokenize our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "IzFfMdh8VlZD"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIDOZlceVlZD"
      },
      "source": [
        "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "NeLABmAIVlZD"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "5tC-WYHAVlZD"
      },
      "source": [
        "### Text to integers (Numericalization)\n",
        "\n",
        "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "60b8y97ZVlZD"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_dataset, ln),\n",
        "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmPfoUoEVlZE",
        "outputId": "7d9e0103-e68f-492a-aab8-53f4e169825b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100, 15, 8, 0, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ],
      "source": [
        "#see some example\n",
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oyIv06bnVlZE",
        "outputId": "ad9ffb2b-b406-4a81-f342-0f018b09e0af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lines'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 256
        }
      ],
      "source": [
        "#we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "#print 1816, for example\n",
        "mapping[1891]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BviRdYLaVlZE",
        "outputId": "cda8036f-d3ea-4875-9548-6fdb0941164c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 257
        }
      ],
      "source": [
        "#let's try unknown vocab\n",
        "mapping[0]\n",
        "#they will all map to <unk> which has 0 as integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6wDpXG-VlZE",
        "outputId": "6e421a62-5a82-4b70-e90c-802634af5930"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ],
      "source": [
        "#let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5e3Rj7dVlZE",
        "outputId": "2307e256-4a95-4c62-ad05-5d40bd7ed212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13937"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ],
      "source": [
        "#check unique vocabularies\n",
        "len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BGZYzhwGVlZF"
      },
      "source": [
        "## 4. Preparing the dataloader\n",
        "\n",
        "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "6YYXxzueVlZF"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 16 # due to gpu limitation\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwhJtB-FVlZF"
      },
      "source": [
        "Create train, val, and test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "f7xlk_vHVlZF"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfo9oEoaVlZG"
      },
      "source": [
        "Let's test the train loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "GcJ043SPVlZG"
      },
      "outputs": [],
      "source": [
        "for en, _, my in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lozckpT8VlZG",
        "outputId": "d68be0ee-0118-4cec-bdd0-d5765a5f08a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([16, 46])\n",
            "Burmese shape:  torch.Size([16, 64])\n"
          ]
        }
      ],
      "source": [
        "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
        "print(\"Burmese shape: \", my.shape)   # (batch_size, seq len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkQiPtzvVlZG"
      },
      "source": [
        "## 5. Design the model\n",
        "\n",
        "<img src=\"https://github.com/MyaMjechal/nlp-a3-machine-translation-language/blob/figures/transformer-encoder.png?raw=1\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQpWXh8VlZS"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "-vkGrgdkVlZS"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        _src    = self.feedforward(src)\n",
        "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnPD7XGDVlZT"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "EY0j7X9_VlZT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                           for _ in range(n_layers)])\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len    = src.shape[1]\n",
        "\n",
        "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, src_len]\n",
        "\n",
        "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        return src\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zvVB-FHVlZU"
      },
      "source": [
        "### Mutli Head Attention Layer\n",
        "\n",
        "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
        "\n",
        "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "shPRBXQIVlZU"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        assert hid_dim % n_heads == 0\n",
        "        self.hid_dim  = hid_dim\n",
        "        self.n_heads  = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout  = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        #src, src, src, src_mask\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        #Q=K=V: [batch_size, src len, hid_dim]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        #Q = [batch_size, n heads, query len, head_dim]\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
        "        #energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        #for making attention to padding to 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        #attention = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
        "        #x = [batch_size, n heads, query len, head dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
        "        #x = [batch_size, query len, n heads, head dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zlovnW-VlZV"
      },
      "source": [
        "### Position-wise Feedforward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "zm648WUgVlZV"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = [batch size, src len, hid dim]\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "6U_gMgEmVlZV"
      },
      "source": [
        "### Decoder Layer\n",
        "\n",
        "<img src = \"../figures/transformer-decoder.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "lntoKe3HVlZW"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "        #attention = [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        _trg = self.feedforward(trg)\n",
        "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic3sUz1zVlZW"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "GMIL-xFYVlZW"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads,\n",
        "                 pf_dim, dropout, device,max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                            for _ in range(n_layers)])\n",
        "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len    = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "        #attention: [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "        #output = [batch_size, trg len, output_dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZkc3QgnVlZX"
      },
      "source": [
        "### Putting them together (become Seq2Seq!)\n",
        "\n",
        "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 1\\\\\n",
        "\\end{matrix}$$\n",
        "\n",
        "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "\\end{matrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "kLqtd3VrVlZX"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "_yEP9eiQVlZY"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "WJeAYXZOVlZY"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "wvBF0QF_VlZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3c5098-962f-4feb-a3b6-efb41abec8e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(13937, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(8016, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=8016, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ],
      "source": [
        "INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
        "OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM,\n",
        "              HID_DIM,\n",
        "              ENC_LAYERS,\n",
        "              ENC_HEADS,\n",
        "              ENC_PF_DIM,\n",
        "              ENC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM,\n",
        "              HID_DIM,\n",
        "              DEC_LAYERS,\n",
        "              DEC_HEADS,\n",
        "              DEC_PF_DIM,\n",
        "              DEC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "f_l096oWVlZZ"
      },
      "outputs": [],
      "source": [
        "# input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "# output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "# hid_dim = 256\n",
        "# enc_layers = 3\n",
        "# dec_layers = 3\n",
        "# enc_heads = 8\n",
        "# dec_heads = 8\n",
        "# enc_pf_dim = 512\n",
        "# dec_pf_dim = 512\n",
        "# enc_dropout = 0.1\n",
        "# dec_dropout = 0.1\n",
        "\n",
        "# SRC_PAD_IDX = PAD_IDX\n",
        "# TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "# enc = Encoder(input_dim,\n",
        "#               hid_dim,\n",
        "#               enc_layers,\n",
        "#               enc_heads,\n",
        "#               enc_pf_dim,\n",
        "#               enc_dropout,\n",
        "#               device)\n",
        "\n",
        "# dec = Decoder(output_dim,\n",
        "#               hid_dim,\n",
        "#               dec_layers,\n",
        "#               dec_heads,\n",
        "#               dec_pf_dim,\n",
        "#               enc_dropout,\n",
        "#               device)\n",
        "\n",
        "# model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "# model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLulasEQVlZZ",
        "outputId": "f1a7ed74-cbcf-4183-c404-f5cc7d5e05de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3567872\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "2052096\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "2052096\n",
            "  8016\n",
            "______\n",
            "11889744\n"
          ]
        }
      ],
      "source": [
        "#we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "CSCOz4DJVlZa"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0005\n",
        "\n",
        "#training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULw5H-YjVlZa"
      },
      "source": [
        "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
        "\n",
        "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
        "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
        "\\end{align*}$$\n",
        "\n",
        "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
        "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "We then calculate our losses and update our parameters as is standard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "kmoup8hGVlZa"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, src_len, trg in loader:\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg    = [batch size, trg len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
        "\n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg    = [batch size * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXtJ93zNVlZa"
      },
      "source": [
        "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "rAu248G6VlZa"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for src, src_len, trg in loader:\n",
        "\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjuJZfMVlZb"
      },
      "source": [
        "### Putting everything together\n",
        "\n",
        "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
        "\n",
        "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "hHRY_A5kVlZb"
      },
      "outputs": [],
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "aOCJw7-kVlZb"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR9sHMVfVlZb",
        "outputId": "03de4c19-776d-4a69-dbd2-1af628913022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 5s\n",
            "\tTrain Loss: 4.931 | Train PPL: 138.483\n",
            "\t Val. Loss: 4.469 |  Val. PPL:  87.272\n",
            "Epoch: 02 | Time: 1m 5s\n",
            "\tTrain Loss: 4.083 | Train PPL:  59.298\n",
            "\t Val. Loss: 4.280 |  Val. PPL:  72.230\n",
            "Epoch: 03 | Time: 1m 5s\n",
            "\tTrain Loss: 3.714 | Train PPL:  41.003\n",
            "\t Val. Loss: 4.245 |  Val. PPL:  69.747\n",
            "Epoch: 04 | Time: 1m 5s\n",
            "\tTrain Loss: 3.431 | Train PPL:  30.911\n",
            "\t Val. Loss: 4.233 |  Val. PPL:  68.933\n",
            "Epoch: 05 | Time: 1m 4s\n",
            "\tTrain Loss: 3.181 | Train PPL:  24.068\n",
            "\t Val. Loss: 4.275 |  Val. PPL:  71.896\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 5\n",
        "clip       = 1\n",
        "\n",
        "save_path = os.path.join(models_dir, f'{model.__class__.__name__}_general.pt')\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "\n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "    #lower perplexity is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "ORHrcWFtVlZb",
        "outputId": "d5b2416c-7e2f-4011-a6d9-f1abc5a8dd11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 281
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu3iVhd7VlZc",
        "outputId": "e4162fcd-9d78-480b-f483-4177de060c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 4.211 | Test PPL:  67.427 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv0TOONVVlZc"
      },
      "source": [
        "## 7. Test on some random news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yYNbdnVgVlZd",
        "outputId": "86b3ac02-9177-4b6e-e6e0-10c4efd4a4a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's all right\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 283
        }
      ],
      "source": [
        "sample[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wRVqLhY_VlZd",
        "outputId": "66b17666-0750-4da1-dd07-acf72d71e442"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ရပါတယ်။'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 284
        }
      ],
      "source": [
        "sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFvkqAtcVlZd",
        "outputId": "21f50b2b-ba93-425c-82ab-bdf4ea5f51f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2, 251,  11,  50,  88,   3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e9rZvOiVlZe",
        "outputId": "c4ee94b8-2154-44d7-cef4-ce6e658c8ea9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, 31, 14, 17,  5,  3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ],
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "t7NlQGfgVlZe"
      },
      "outputs": [],
      "source": [
        "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "jcka-c9_VlZe"
      },
      "outputs": [],
      "source": [
        "trg_text = trg_text.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4_IZQSiVlZe",
        "outputId": "7731d527-025a-4710-cab5-e49244da8701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 6]), torch.Size([1, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ],
      "source": [
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "IgAWd7gEVlZe"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "c7_ewO5rVlZe"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUuow44wVlZf",
        "outputId": "33e327b6-7e33-4b10-94ec-2e8b9fcf4181"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ],
      "source": [
        "output.shape #batch_size, trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n_S_BF1VlZf"
      },
      "source": [
        "Since batch size is 1, we just take off that dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "5uVcMsF_VlZf"
      },
      "outputs": [],
      "source": [
        "output = output.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7xOyaFAVlZg",
        "outputId": "f44122a2-2f00-499d-e3c4-4f0a82d3ab14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqKV4QRVlZg"
      },
      "source": [
        "We shall remove the first token since it's zeroes anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E_NnF7GVlZg",
        "outputId": "4f34ef1d-0257-4d08-dffc-af8ef8d8e102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ],
      "source": [
        "output = output[1:]\n",
        "output.shape #trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE9omPNdVlZg"
      },
      "source": [
        "Then we just take the top token with highest probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "ImJHvoVOVlZh"
      },
      "outputs": [],
      "source": [
        "output_max = output.argmax(1) #returns max indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL9luNkpVlZh",
        "outputId": "ed2027cb-39e9-426a-af02-fd952ed3107a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([35, 17,  5,  3, 17], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ],
      "source": [
        "output_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w48ZU9RSVlZh"
      },
      "source": [
        "Get the mapping of the target language"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ],
      "metadata": {
        "id": "IukY4P0pqCy_"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2bfH6mmVlZh",
        "outputId": "f8969a6e-cdc2-4f03-a1fb-c879aec44210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "တာ\n",
            "တယ်\n",
            "။\n",
            "<eos>\n",
            "တယ်\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fov4Y7X9VlZh"
      },
      "source": [
        "## 8. Attention\n",
        "\n",
        "Let's display the attentions to understand how the source text links with the generated text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syuon5H6VlZh",
        "outputId": "be618225-48aa-40e3-bb14-f49eb542fdd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ],
      "source": [
        "attentions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJG9JwA5VlZi"
      },
      "source": [
        "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6o_SVX_VlZi",
        "outputId": "cf55cf72-389c-4b88-976b-950a64c58de0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ],
      "source": [
        "attention = attentions[0, 0, :, :]\n",
        "attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfuK6kkbVlZi",
        "outputId": "4bf4541d-1f1b-410d-e2eb-1c15521c9ac4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'That', \"'s\", 'all', 'right', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ],
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
        "src_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0WbZm7lVlZi",
        "outputId": "cb6b1a31-537a-400c-89b9-4c80f5d6464e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'တာ', 'တယ်', '။', '<eos>', 'တယ်']"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ],
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "MpZToAbEVlZi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "    ax.tick_params(labelsize=10)\n",
        "\n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence\n",
        "\n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZZ-y3RkYVlZj",
        "outputId": "fa6354e9-f781-49fe-a90c-3650d3859ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-304-08ff35c238c4>:17: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-304-08ff35c238c4>:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels(y_ticks)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4112 (\\N{MYANMAR LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4140 (\\N{MYANMAR VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4122 (\\N{MYANMAR LETTER YA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4154 (\\N{MYANMAR SIGN ASAT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4171 (\\N{MYANMAR SIGN SECTION}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display_attention(src_tokens, trg_tokens, attention)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "vocab = {\n",
        "    'token_transform': token_transform,\n",
        "    'vocab_transform': vocab_transform,\n",
        "}\n",
        "pkl_save_path = os.path.join(models_dir, 'mtt_general.pkl')\n",
        "pickle.dump(vocab, open(pkl_save_path, 'wb'))"
      ],
      "metadata": {
        "id": "2MZL103C3vPN"
      },
      "execution_count": 306,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}