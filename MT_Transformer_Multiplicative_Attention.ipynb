{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zH0K5vGVlY2"
      },
      "source": [
        "# Machine Translation + Transformer\n",
        "\n",
        "<img src = \"../figures/transformer1.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchdata\n",
        "# !pip install torch==2.2.0 torchtext==0.17.0\n",
        "# !pip install datasets\n",
        "# !pip install pyidaungsu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z-XorRi_V0qN"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtELAKwuZu7I",
        "outputId": "4b5cfd17-0ca4-409a-fb1a-99585c7dae8d"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 'models' directory if it doesn't exist\n",
        "import os\n",
        "models_dir = \"/content/drive/MyDrive/models\"  # Replace with your desired path\n",
        "os.makedirs(models_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Rg3U81vEZ_qC"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1achhdMOVlY4",
        "outputId": "d0ac128a-047b-48f5-9d1b-03b867084788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "vicj79XSVlY7"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WggQSyw1VlY8",
        "outputId": "1bf8576a-b395-4609-ca65-55c51d04088e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9XZX5y12VlY9",
        "outputId": "116dd74e-0f4a-4cf6-ac50-24a4a63abe10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.17.0+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "IACCellNVlY-"
      },
      "source": [
        "## 1. ETL: Loading the dataset\n",
        "\n",
        "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "import pyidaungsu"
      ],
      "metadata": {
        "id": "NgYgL7qzk50Q"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(\"myamjechal/en_my_myanmar-xnli_small\")"
      ],
      "metadata": {
        "id": "OgOpgUmlJXKH"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch only 20,000 rows for train dataset due to execution time\n",
        "train_dataset = [(row['en'], row['my']) for row in dataset['train']][:15000]\n",
        "val_dataset = [(row['en'], row['my']) for row in dataset['validation']]\n",
        "test_dataset = [(row['en'], row['my']) for row in dataset['test']]"
      ],
      "metadata": {
        "id": "nZrEygAAl2jI"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1cyGTdbu4Dz",
        "outputId": "20285657-791a-4741-cdcc-591bb833871a"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "-pbb8qLfVlY_"
      },
      "source": [
        "## 2. EDA - simple investigation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = [row for row in train_dataset if row[0] is not None and row[1] is not None]\n",
        "val_dataset = [row for row in val_dataset if row[0] is not None and row[1] is not None]\n",
        "test_dataset = [row for row in test_dataset if row[0] is not None and row[1] is not None]"
      ],
      "metadata": {
        "id": "zz_7V_qZLfGI"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's take a look at one example of train\n",
        "sample = next(iter(train_dataset))\n",
        "sample"
      ],
      "metadata": {
        "id": "ZbsdSNOiVuzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ee12b6-363a-4839-b6e2-ec6e39610e14"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqiBkYqbVlZA",
        "outputId": "1ad4708c-b239-4f0d-e884-e41acb1bf5d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14978"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "train_size = len(list(iter(train_dataset)))\n",
        "train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfuvGwXIVlZB",
        "outputId": "603fcb36-23ef-40b2-efed-8379e58715ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2490"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "source": [
        "val_size = len(list(iter(val_dataset)))\n",
        "val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_g-UifpVlZB",
        "outputId": "2fb23e18-ef9b-473a-8ad8-b941c40225d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5010"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ],
      "source": [
        "test_size = len(list(iter(test_dataset)))\n",
        "test_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "YQRI054OVlZB"
      },
      "source": [
        "## 3. Preprocessing\n",
        "\n",
        "### Tokenizing\n",
        "\n",
        "**Note**: the models must first be downloaded using the following on the command line:\n",
        "```\n",
        "python3 -m spacy download en_core_web_sm\n",
        "python3 -m spacy download de_core_news_sm\n",
        "```\n",
        "\n",
        "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JkEhOy8Pb0qi"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "Kc-yzoDVVlZC"
      },
      "outputs": [],
      "source": [
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'my'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_tokenizer(text):\n",
        "  return pyidaungsu.tokenize(text, form='word')"
      ],
      "metadata": {
        "id": "KMbboChFa9GF"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In2raKhWVlZC",
        "outputId": "42e3b920-701b-4876-c844-beb8d7d3c54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TRG_LANGUAGE] = my_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx97Q3TEbKQv",
        "outputId": "b5f428c9-0421-4857-c648-5895f52f8e39"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDWy-On8VlZC",
        "outputId": "f84126a1-42df-4a2f-ced4-31219610d6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  ရပါတယ်။\n",
            "Tokenization:  ['ရပါတယ်။']\n"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the english part\n",
        "print(\"Sentence: \", sample[1])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsgLYX8tVlZC"
      },
      "source": [
        "A function to tokenize our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "IzFfMdh8VlZD"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIDOZlceVlZD"
      },
      "source": [
        "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "NeLABmAIVlZD"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "5tC-WYHAVlZD"
      },
      "source": [
        "### Text to integers (Numericalization)\n",
        "\n",
        "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "60b8y97ZVlZD"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_dataset, ln),\n",
        "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmPfoUoEVlZE",
        "outputId": "5758e0dd-0225-4890-883b-501106cc2009"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100, 15, 8, 0, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "#see some example\n",
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oyIv06bnVlZE",
        "outputId": "f913bf3b-2c8d-4c3c-9459-f315c3a2bb1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lines'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 179
        }
      ],
      "source": [
        "#we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "#print 1816, for example\n",
        "mapping[1891]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BviRdYLaVlZE",
        "outputId": "8652f6e8-992e-424f-e65e-41f904a99cc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "#let's try unknown vocab\n",
        "mapping[0]\n",
        "#they will all map to <unk> which has 0 as integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6wDpXG-VlZE",
        "outputId": "e2924604-3bd5-47f3-da2d-cfadca7ed994"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "#let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5e3Rj7dVlZE",
        "outputId": "a3f8f76b-a2f2-4ff6-c720-8881b22bde38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13937"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "#check unique vocabularies\n",
        "len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BGZYzhwGVlZF"
      },
      "source": [
        "## 4. Preparing the dataloader\n",
        "\n",
        "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "6YYXxzueVlZF"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 16 # due to gpu limitation\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwhJtB-FVlZF"
      },
      "source": [
        "Create train, val, and test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "f7xlk_vHVlZF"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfo9oEoaVlZG"
      },
      "source": [
        "Let's test the train loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "GcJ043SPVlZG"
      },
      "outputs": [],
      "source": [
        "for en, _, my in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lozckpT8VlZG",
        "outputId": "f1001a36-55f3-4b36-be47-d800f8cb8a83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([16, 46])\n",
            "Burmese shape:  torch.Size([16, 64])\n"
          ]
        }
      ],
      "source": [
        "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
        "print(\"Burmese shape: \", my.shape)   # (batch_size, seq len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkQiPtzvVlZG"
      },
      "source": [
        "## 5. Design the model\n",
        "\n",
        "<img src=\"https://github.com/MyaMjechal/nlp-a3-machine-translation-language/blob/figures/transformer-encoder.png?raw=1\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQpWXh8VlZS"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "-vkGrgdkVlZS"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        _src    = self.feedforward(src)\n",
        "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnPD7XGDVlZT"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "EY0j7X9_VlZT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                           for _ in range(n_layers)])\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len    = src.shape[1]\n",
        "\n",
        "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, src_len]\n",
        "\n",
        "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        return src\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zvVB-FHVlZU"
      },
      "source": [
        "### Mutli Head Attention Layer\n",
        "\n",
        "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
        "\n",
        "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "shPRBXQIVlZU"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        assert hid_dim % n_heads == 0\n",
        "        self.hid_dim  = hid_dim\n",
        "        self.n_heads  = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        # multiplicative attention layer\n",
        "        self.w        = nn.Linear(self.head_dim, self.head_dim)\n",
        "\n",
        "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout  = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        #src, src, src, src_mask\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        #Q=K=V: [batch_size, src len, hid_dim]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        #Q = [batch_size, n heads, query len, head_dim]\n",
        "\n",
        "        # add scaled multiplicative attention\n",
        "        energy = torch.matmul(Q, self.w(K).permute(0, 1, 3, 2)) / self.scale\n",
        "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
        "        #energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        #for making attention to padding to 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        #attention = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
        "        #x = [batch_size, n heads, query len, head dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
        "        #x = [batch_size, query len, n heads, head dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zlovnW-VlZV"
      },
      "source": [
        "### Position-wise Feedforward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "zm648WUgVlZV"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = [batch size, src len, hid dim]\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "6U_gMgEmVlZV"
      },
      "source": [
        "### Decoder Layer\n",
        "\n",
        "<img src = \"../figures/transformer-decoder.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "lntoKe3HVlZW"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "        #attention = [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        _trg = self.feedforward(trg)\n",
        "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic3sUz1zVlZW"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "GMIL-xFYVlZW"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads,\n",
        "                 pf_dim, dropout, device,max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                            for _ in range(n_layers)])\n",
        "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len    = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "        #attention: [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "        #output = [batch_size, trg len, output_dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZkc3QgnVlZX"
      },
      "source": [
        "### Putting them together (become Seq2Seq!)\n",
        "\n",
        "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 1\\\\\n",
        "\\end{matrix}$$\n",
        "\n",
        "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "\\end{matrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "kLqtd3VrVlZX"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "_yEP9eiQVlZY"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "WJeAYXZOVlZY"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "wvBF0QF_VlZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84637c1-c0f3-4d64-9ce2-63a6e81a0435"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(13937, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(8016, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=8016, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ],
      "source": [
        "INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
        "OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM,\n",
        "              HID_DIM,\n",
        "              ENC_LAYERS,\n",
        "              ENC_HEADS,\n",
        "              ENC_PF_DIM,\n",
        "              ENC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM,\n",
        "              HID_DIM,\n",
        "              DEC_LAYERS,\n",
        "              DEC_HEADS,\n",
        "              DEC_PF_DIM,\n",
        "              DEC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "f_l096oWVlZZ"
      },
      "outputs": [],
      "source": [
        "# input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "# output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "# hid_dim = 256\n",
        "# enc_layers = 3\n",
        "# dec_layers = 3\n",
        "# enc_heads = 8\n",
        "# dec_heads = 8\n",
        "# enc_pf_dim = 512\n",
        "# dec_pf_dim = 512\n",
        "# enc_dropout = 0.1\n",
        "# dec_dropout = 0.1\n",
        "\n",
        "# SRC_PAD_IDX = PAD_IDX\n",
        "# TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "# enc = Encoder(input_dim,\n",
        "#               hid_dim,\n",
        "#               enc_layers,\n",
        "#               enc_heads,\n",
        "#               enc_pf_dim,\n",
        "#               enc_dropout,\n",
        "#               device)\n",
        "\n",
        "# dec = Decoder(output_dim,\n",
        "#               hid_dim,\n",
        "#               dec_layers,\n",
        "#               dec_heads,\n",
        "#               dec_pf_dim,\n",
        "#               enc_dropout,\n",
        "#               device)\n",
        "\n",
        "# model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "# model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLulasEQVlZZ",
        "outputId": "3dd8d8dc-2311-4f39-ede2-1d9eadc0155f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3567872\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "2052096\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "2052096\n",
            "  8016\n",
            "______\n",
            "11899248\n"
          ]
        }
      ],
      "source": [
        "#we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "CSCOz4DJVlZa"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0005\n",
        "\n",
        "#training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULw5H-YjVlZa"
      },
      "source": [
        "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
        "\n",
        "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
        "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
        "\\end{align*}$$\n",
        "\n",
        "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
        "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "We then calculate our losses and update our parameters as is standard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "kmoup8hGVlZa"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, src_len, trg in loader:\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg    = [batch size, trg len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
        "\n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg    = [batch size * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXtJ93zNVlZa"
      },
      "source": [
        "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "rAu248G6VlZa"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for src, src_len, trg in loader:\n",
        "\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjuJZfMVlZb"
      },
      "source": [
        "### Putting everything together\n",
        "\n",
        "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
        "\n",
        "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "hHRY_A5kVlZb"
      },
      "outputs": [],
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "aOCJw7-kVlZb"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR9sHMVfVlZb",
        "outputId": "ffbc0894-06b9-474e-8246-3766d4d57527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 6s\n",
            "\tTrain Loss: 4.916 | Train PPL: 136.392\n",
            "\t Val. Loss: 4.436 |  Val. PPL:  84.415\n",
            "Epoch: 02 | Time: 1m 6s\n",
            "\tTrain Loss: 4.077 | Train PPL:  58.990\n",
            "\t Val. Loss: 4.282 |  Val. PPL:  72.393\n",
            "Epoch: 03 | Time: 1m 5s\n",
            "\tTrain Loss: 3.715 | Train PPL:  41.059\n",
            "\t Val. Loss: 4.240 |  Val. PPL:  69.411\n",
            "Epoch: 04 | Time: 1m 5s\n",
            "\tTrain Loss: 3.435 | Train PPL:  31.033\n",
            "\t Val. Loss: 4.224 |  Val. PPL:  68.285\n",
            "Epoch: 05 | Time: 1m 6s\n",
            "\tTrain Loss: 3.187 | Train PPL:  24.220\n",
            "\t Val. Loss: 4.295 |  Val. PPL:  73.365\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 5\n",
        "clip       = 1\n",
        "\n",
        "save_path = os.path.join(models_dir, f'{model.__class__.__name__}_multiplicative.pt')\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "\n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "    #lower perplexity is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "ORHrcWFtVlZb",
        "outputId": "be46f41a-7039-41d4-a146-0cafe0e221d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 204
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu3iVhd7VlZc",
        "outputId": "ec836be2-9184-4146-853b-24b8400bb1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 4.209 | Test PPL:  67.308 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv0TOONVVlZc"
      },
      "source": [
        "## 7. Test on some random news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yYNbdnVgVlZd",
        "outputId": "b1aefd66-bd2e-42bd-a48e-6eb48f3a8682"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's all right\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 206
        }
      ],
      "source": [
        "sample[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wRVqLhY_VlZd",
        "outputId": "5711e641-276a-466c-aa75-89ba4195d6e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ရပါတယ်။'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 207
        }
      ],
      "source": [
        "sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFvkqAtcVlZd",
        "outputId": "271c201d-3e89-4a1a-fd8c-e09adc5c1def"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2, 251,  11,  50,  88,   3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e9rZvOiVlZe",
        "outputId": "031c7ef3-5fce-4dd8-ce82-b67db1ddcab6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, 31, 14, 17,  5,  3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "t7NlQGfgVlZe"
      },
      "outputs": [],
      "source": [
        "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "jcka-c9_VlZe"
      },
      "outputs": [],
      "source": [
        "trg_text = trg_text.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4_IZQSiVlZe",
        "outputId": "fd01ed42-626a-4711-9b0c-8432015e311f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 6]), torch.Size([1, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ],
      "source": [
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "IgAWd7gEVlZe"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "c7_ewO5rVlZe"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUuow44wVlZf",
        "outputId": "32a64c98-8aee-4412-b172-8e6ffb834e1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "output.shape #batch_size, trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n_S_BF1VlZf"
      },
      "source": [
        "Since batch size is 1, we just take off that dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "5uVcMsF_VlZf"
      },
      "outputs": [],
      "source": [
        "output = output.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7xOyaFAVlZg",
        "outputId": "074ee172-a8e1-4e45-a3c1-92c3e0b42e6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqKV4QRVlZg"
      },
      "source": [
        "We shall remove the first token since it's zeroes anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E_NnF7GVlZg",
        "outputId": "de4b0e15-2c18-4bc0-e8e4-1b3d67267fd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ],
      "source": [
        "output = output[1:]\n",
        "output.shape #trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE9omPNdVlZg"
      },
      "source": [
        "Then we just take the top token with highest probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "ImJHvoVOVlZh"
      },
      "outputs": [],
      "source": [
        "output_max = output.argmax(1) #returns max indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL9luNkpVlZh",
        "outputId": "c2724474-a7b6-4f62-b0bf-27cca694a203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([35, 17,  5,  3,  3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ],
      "source": [
        "output_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w48ZU9RSVlZh"
      },
      "source": [
        "Get the mapping of the target language"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ],
      "metadata": {
        "id": "IukY4P0pqCy_"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2bfH6mmVlZh",
        "outputId": "1c58fdf5-2e34-4295-ae45-1659171ad4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "တာ\n",
            "တယ်\n",
            "။\n",
            "<eos>\n",
            "<eos>\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fov4Y7X9VlZh"
      },
      "source": [
        "## 8. Attention\n",
        "\n",
        "Let's display the attentions to understand how the source text links with the generated text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syuon5H6VlZh",
        "outputId": "00dbe85e-8396-4d14-e53d-cd3cbfa6eef3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ],
      "source": [
        "attentions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJG9JwA5VlZi"
      },
      "source": [
        "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6o_SVX_VlZi",
        "outputId": "230040b1-d778-49ce-c732-4e21989c8c4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ],
      "source": [
        "attention = attentions[0, 0, :, :]\n",
        "attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfuK6kkbVlZi",
        "outputId": "9e54ba2c-9f73-4351-dbef-3bae5b9d9fa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'That', \"'s\", 'all', 'right', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ],
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
        "src_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0WbZm7lVlZi",
        "outputId": "24b23be8-a34d-4b85-9b38-e45c053156c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'တာ', 'တယ်', '။', '<eos>', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ],
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "MpZToAbEVlZi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "    ax.tick_params(labelsize=10)\n",
        "\n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence\n",
        "\n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZZ-y3RkYVlZj",
        "outputId": "dc9c15ae-e4ff-4ca0-91cd-9417eab19d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-227-08ff35c238c4>:17: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-227-08ff35c238c4>:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels(y_ticks)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4112 (\\N{MYANMAR LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4140 (\\N{MYANMAR VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4122 (\\N{MYANMAR LETTER YA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4154 (\\N{MYANMAR SIGN ASAT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4171 (\\N{MYANMAR SIGN SECTION}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display_attention(src_tokens, trg_tokens, attention)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "vocab = {\n",
        "    'token_transform': token_transform,\n",
        "    'vocab_transform': vocab_transform,\n",
        "}\n",
        "pkl_save_path = os.path.join(models_dir, 'mtt_multiplicative.pkl')\n",
        "pickle.dump(vocab, open(pkl_save_path, 'wb'))"
      ],
      "metadata": {
        "id": "2MZL103C3vPN"
      },
      "execution_count": 229,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}