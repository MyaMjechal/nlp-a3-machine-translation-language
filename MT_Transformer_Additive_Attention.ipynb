{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zH0K5vGVlY2"
      },
      "source": [
        "# Machine Translation + Transformer\n",
        "\n",
        "<img src = \"../figures/transformer1.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchdata\n",
        "# !pip install torch==2.2.0 torchtext==0.17.0\n",
        "# !pip install datasets\n",
        "# !pip install pyidaungsu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z-XorRi_V0qN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1achhdMOVlY4",
        "outputId": "488f7393-2d30-4ff9-8711-92d256418011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vicj79XSVlY7"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WggQSyw1VlY8",
        "outputId": "ed4bf79d-6706-4dd2-a739-7de2eaba0e7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9XZX5y12VlY9",
        "outputId": "77b88e82-9151-4ff3-a805-f819aca689e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.17.0+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "IACCellNVlY-"
      },
      "source": [
        "## 1. ETL: Loading the dataset\n",
        "\n",
        "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "import pyidaungsu"
      ],
      "metadata": {
        "id": "NgYgL7qzk50Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(\"myamjechal/en_my_myanmar-xnli_small\")"
      ],
      "metadata": {
        "id": "OgOpgUmlJXKH",
        "outputId": "da179b09-5b99-422b-fbf4-9cd75df68094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch only 20,000 rows for train dataset due to execution time\n",
        "train_dataset = [(row['en'], row['my']) for row in dataset['train']][:15000]\n",
        "val_dataset = [(row['en'], row['my']) for row in dataset['validation']]\n",
        "test_dataset = [(row['en'], row['my']) for row in dataset['test']]"
      ],
      "metadata": {
        "id": "nZrEygAAl2jI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1cyGTdbu4Dz",
        "outputId": "2f9743c2-00b8-44c6-91b3-a3c71cde31c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "-pbb8qLfVlY_"
      },
      "source": [
        "## 2. EDA - simple investigation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = [row for row in train_dataset if row[0] is not None and row[1] is not None]\n",
        "val_dataset = [row for row in val_dataset if row[0] is not None and row[1] is not None]\n",
        "test_dataset = [row for row in test_dataset if row[0] is not None and row[1] is not None]"
      ],
      "metadata": {
        "id": "zz_7V_qZLfGI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's take a look at one example of train\n",
        "sample = next(iter(train_dataset))\n",
        "sample"
      ],
      "metadata": {
        "id": "ZbsdSNOiVuzv",
        "outputId": "2e5d2548-38cb-4bec-c4dc-f3cf236ab2d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqiBkYqbVlZA",
        "outputId": "d42d4b77-55bd-41c2-fc2e-3d219d8e53cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14978"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_size = len(list(iter(train_dataset)))\n",
        "train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfuvGwXIVlZB",
        "outputId": "0a8de75e-71b8-4252-d616-7c02942a5ccf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2490"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "val_size = len(list(iter(val_dataset)))\n",
        "val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_g-UifpVlZB",
        "outputId": "5899f830-6860-4353-8497-d1f2c1ba8146"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5010"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "test_size = len(list(iter(test_dataset)))\n",
        "test_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "YQRI054OVlZB"
      },
      "source": [
        "## 3. Preprocessing\n",
        "\n",
        "### Tokenizing\n",
        "\n",
        "**Note**: the models must first be downloaded using the following on the command line:\n",
        "```\n",
        "python3 -m spacy download en_core_web_sm\n",
        "python3 -m spacy download de_core_news_sm\n",
        "```\n",
        "\n",
        "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JkEhOy8Pb0qi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Kc-yzoDVVlZC"
      },
      "outputs": [],
      "source": [
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'my'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_tokenizer(text):\n",
        "  return pyidaungsu.tokenize(text, form='word')"
      ],
      "metadata": {
        "id": "KMbboChFa9GF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "In2raKhWVlZC"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TRG_LANGUAGE] = my_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx97Q3TEbKQv",
        "outputId": "bc07de6e-0142-46d5-c924-18d2fbf535ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"That's all right\", 'ရပါတယ်။')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDWy-On8VlZC",
        "outputId": "31aaa756-8778-4e7a-8176-4cdd381e85c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  ရပါတယ်။\n",
            "Tokenization:  ['ရပါတယ်။']\n"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the english part\n",
        "print(\"Sentence: \", sample[1])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsgLYX8tVlZC"
      },
      "source": [
        "A function to tokenize our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IzFfMdh8VlZD"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIDOZlceVlZD"
      },
      "source": [
        "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NeLABmAIVlZD"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "5tC-WYHAVlZD"
      },
      "source": [
        "### Text to integers (Numericalization)\n",
        "\n",
        "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "60b8y97ZVlZD"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_dataset, ln),\n",
        "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmPfoUoEVlZE",
        "outputId": "6248db74-04cc-433a-a96c-fb170d243754"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100, 15, 8, 0, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#see some example\n",
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oyIv06bnVlZE",
        "outputId": "48801cc1-f1bf-4dec-9af4-705e7095bcb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lines'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "#print 1816, for example\n",
        "mapping[1891]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BviRdYLaVlZE",
        "outputId": "9d85a99c-611b-45d7-e763-728b31c96331"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#let's try unknown vocab\n",
        "mapping[0]\n",
        "#they will all map to <unk> which has 0 as integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6wDpXG-VlZE",
        "outputId": "e3c96174-b694-4600-f376-cf382c832627"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5e3Rj7dVlZE",
        "outputId": "7ff13854-1698-4357-f248-db8349b84355"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13937"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#check unique vocabularies\n",
        "len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BGZYzhwGVlZF"
      },
      "source": [
        "## 4. Preparing the dataloader\n",
        "\n",
        "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6YYXxzueVlZF"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 16 # due to gpu limitation\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwhJtB-FVlZF"
      },
      "source": [
        "Create train, val, and test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "f7xlk_vHVlZF"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfo9oEoaVlZG"
      },
      "source": [
        "Let's test the train loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GcJ043SPVlZG"
      },
      "outputs": [],
      "source": [
        "for en, _, my in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lozckpT8VlZG",
        "outputId": "52080721-6c1d-4099-c1c3-7b6c7a46a064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([16, 46])\n",
            "Burmese shape:  torch.Size([16, 64])\n"
          ]
        }
      ],
      "source": [
        "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
        "print(\"Burmese shape: \", my.shape)   # (batch_size, seq len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkQiPtzvVlZG"
      },
      "source": [
        "## 5. Design the model\n",
        "\n",
        "<img src=\"https://github.com/MyaMjechal/nlp-a3-machine-translation-language/blob/figures/transformer-encoder.png?raw=1\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQpWXh8VlZS"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-vkGrgdkVlZS"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        _src    = self.feedforward(src)\n",
        "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnPD7XGDVlZT"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EY0j7X9_VlZT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 700):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                           for _ in range(n_layers)])\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len    = src.shape[1]\n",
        "\n",
        "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, src_len]\n",
        "\n",
        "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        return src\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zvVB-FHVlZU"
      },
      "source": [
        "### Mutli Head Attention Layer\n",
        "\n",
        "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
        "\n",
        "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "shPRBXQIVlZU"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        assert hid_dim % n_heads == 0\n",
        "        self.hid_dim  = hid_dim\n",
        "        self.n_heads  = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "         # Linear layers for additive attention\n",
        "        self.W1 = nn.Linear(self.head_dim, self.head_dim)  # W1 for Q\n",
        "        self.W2 = nn.Linear(self.head_dim, self.head_dim)  # W2 for K\n",
        "        self.vt = nn.Linear(self.head_dim, 1)  # v^T for additive attention\n",
        "\n",
        "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout  = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        #src, src, src, src_mask\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        #Q=K=V: [batch_size, src len, hid_dim]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        #Q = [batch_size, n heads, query len, head_dim]\n",
        "\n",
        "        # Additive attention computation\n",
        "        # Add extra dimensions for broadcasting\n",
        "        Q_expanded = Q.unsqueeze(3)  # [batch_size, n_heads, query_len, 1, head_dim]\n",
        "        K_expanded = K.unsqueeze(2)  # [batch_size, n_heads, 1, key_len, head_dim]\n",
        "\n",
        "        # Compute W1(Q) + W2(K)\n",
        "        W1Q = self.W1(Q_expanded)  # [batch_size, n_heads, query_len, 1, head_dim]\n",
        "        W2K = self.W2(K_expanded)  # [batch_size, n_heads, 1, key_len, head_dim]\n",
        "        energy = torch.tanh(W1Q + W2K)  # [batch_size, n_heads, query_len, key_len, head_dim]\n",
        "\n",
        "        # Compute v^T * tanh(W1(Q) + W2(K))\n",
        "        energy = self.vt(energy).squeeze(-1)  # [batch_size, n_heads, query_len, key_len]\n",
        "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
        "        #energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        #for making attention to padding to 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        #attention = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
        "        #x = [batch_size, n heads, query len, head dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
        "        #x = [batch_size, query len, n heads, head dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zlovnW-VlZV"
      },
      "source": [
        "### Position-wise Feedforward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zm648WUgVlZV"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = [batch size, src len, hid dim]\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "6U_gMgEmVlZV"
      },
      "source": [
        "### Decoder Layer\n",
        "\n",
        "<img src = \"../figures/transformer-decoder.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lntoKe3HVlZW"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "        #attention = [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        _trg = self.feedforward(trg)\n",
        "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic3sUz1zVlZW"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GMIL-xFYVlZW"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads,\n",
        "                 pf_dim, dropout, device,max_length = 700):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                            for _ in range(n_layers)])\n",
        "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len    = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "        #attention: [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "        #output = [batch_size, trg len, output_dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZkc3QgnVlZX"
      },
      "source": [
        "### Putting them together (become Seq2Seq!)\n",
        "\n",
        "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 1\\\\\n",
        "\\end{matrix}$$\n",
        "\n",
        "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "\\end{matrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kLqtd3VrVlZX"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "_yEP9eiQVlZY"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WJeAYXZOVlZY"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "wvBF0QF_VlZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dcb18a-d4f8-4593-950b-0392a3a3f2c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(13937, 256)\n",
              "    (pos_embedding): Embedding(700, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W1): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (W2): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(8016, 256)\n",
              "    (pos_embedding): Embedding(700, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W1): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (W2): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W1): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (W2): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=8016, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
        "OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM,\n",
        "              HID_DIM,\n",
        "              ENC_LAYERS,\n",
        "              ENC_HEADS,\n",
        "              ENC_PF_DIM,\n",
        "              ENC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM,\n",
        "              HID_DIM,\n",
        "              DEC_LAYERS,\n",
        "              DEC_HEADS,\n",
        "              DEC_PF_DIM,\n",
        "              DEC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "f_l096oWVlZZ"
      },
      "outputs": [],
      "source": [
        "# input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "# output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "# hid_dim = 256\n",
        "# enc_layers = 3\n",
        "# dec_layers = 3\n",
        "# enc_heads = 8\n",
        "# dec_heads = 8\n",
        "# enc_pf_dim = 512\n",
        "# dec_pf_dim = 512\n",
        "# enc_dropout = 0.1\n",
        "# dec_dropout = 0.1\n",
        "\n",
        "# SRC_PAD_IDX = PAD_IDX\n",
        "# TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "# enc = Encoder(input_dim,\n",
        "#               hid_dim,\n",
        "#               enc_layers,\n",
        "#               enc_heads,\n",
        "#               enc_pf_dim,\n",
        "#               enc_dropout,\n",
        "#               device)\n",
        "\n",
        "# dec = Decoder(output_dim,\n",
        "#               hid_dim,\n",
        "#               dec_layers,\n",
        "#               dec_heads,\n",
        "#               dec_pf_dim,\n",
        "#               enc_dropout,\n",
        "#               device)\n",
        "\n",
        "# model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "# model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLulasEQVlZZ",
        "outputId": "ffcba754-87f8-4eef-dcbe-1b4c5bccbc8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3567872\n",
            "179200\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "2052096\n",
            "179200\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "2052096\n",
            "  8016\n",
            "______\n",
            "12011449\n"
          ]
        }
      ],
      "source": [
        "#we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "CSCOz4DJVlZa"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0005\n",
        "\n",
        "#training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULw5H-YjVlZa"
      },
      "source": [
        "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
        "\n",
        "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
        "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
        "\\end{align*}$$\n",
        "\n",
        "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
        "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "We then calculate our losses and update our parameters as is standard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kmoup8hGVlZa"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, src_len, trg in loader:\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg    = [batch size, trg len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
        "\n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg    = [batch size * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXtJ93zNVlZa"
      },
      "source": [
        "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rAu248G6VlZa"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for src, src_len, trg in loader:\n",
        "\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjuJZfMVlZb"
      },
      "source": [
        "### Putting everything together\n",
        "\n",
        "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
        "\n",
        "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "hHRY_A5kVlZb"
      },
      "outputs": [],
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "aOCJw7-kVlZb"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR9sHMVfVlZb",
        "outputId": "9cf10023-c229-40b9-cd9a-1679d74cee7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 25s\n",
            "\tTrain Loss: 4.882 | Train PPL: 131.939\n",
            "\t Val. Loss: 4.398 |  Val. PPL:  81.277\n",
            "Epoch: 02 | Time: 1m 24s\n",
            "\tTrain Loss: 4.033 | Train PPL:  56.421\n",
            "\t Val. Loss: 4.242 |  Val. PPL:  69.538\n",
            "Epoch: 03 | Time: 1m 24s\n",
            "\tTrain Loss: 3.670 | Train PPL:  39.244\n",
            "\t Val. Loss: 4.232 |  Val. PPL:  68.860\n",
            "Epoch: 04 | Time: 1m 24s\n",
            "\tTrain Loss: 3.386 | Train PPL:  29.542\n",
            "\t Val. Loss: 4.235 |  Val. PPL:  69.052\n",
            "Epoch: 05 | Time: 1m 24s\n",
            "\tTrain Loss: 3.145 | Train PPL:  23.212\n",
            "\t Val. Loss: 4.268 |  Val. PPL:  71.393\n",
            "Epoch: 06 | Time: 1m 24s\n",
            "\tTrain Loss: 2.923 | Train PPL:  18.599\n",
            "\t Val. Loss: 4.318 |  Val. PPL:  75.012\n",
            "Epoch: 07 | Time: 1m 24s\n",
            "\tTrain Loss: 2.714 | Train PPL:  15.088\n",
            "\t Val. Loss: 4.458 |  Val. PPL:  86.285\n",
            "Epoch: 08 | Time: 1m 24s\n",
            "\tTrain Loss: 2.529 | Train PPL:  12.539\n",
            "\t Val. Loss: 4.537 |  Val. PPL:  93.410\n",
            "Epoch: 09 | Time: 1m 24s\n",
            "\tTrain Loss: 2.357 | Train PPL:  10.557\n",
            "\t Val. Loss: 4.691 |  Val. PPL: 108.914\n",
            "Epoch: 10 | Time: 1m 24s\n",
            "\tTrain Loss: 2.207 | Train PPL:   9.093\n",
            "\t Val. Loss: 4.799 |  Val. PPL: 121.354\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'models/{model.__class__.__name__}_additive.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "\n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "    #lower perplexity is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "ORHrcWFtVlZb",
        "outputId": "57998944-e080-404a-831b-9cb4e0a81a9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu3iVhd7VlZc",
        "outputId": "156f8ad0-8641-45e7-a454-ff74e7cb3aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 4.218 | Test PPL:  67.865 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv0TOONVVlZc"
      },
      "source": [
        "## 7. Test on some random news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yYNbdnVgVlZd",
        "outputId": "aa16f02a-f605-420a-8fcd-3f84b3e9433d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's all right\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "sample[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wRVqLhY_VlZd",
        "outputId": "591b6d7a-1130-475e-b29a-09b1a50b863b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ရပါတယ်။'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFvkqAtcVlZd",
        "outputId": "b5a731c7-57ce-4c01-d3fa-8967001342bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2, 251,  11,  50,  88,   3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e9rZvOiVlZe",
        "outputId": "2a15193c-27e3-45c9-acd2-0d75bd45af8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, 31, 14, 17,  5,  3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "t7NlQGfgVlZe"
      },
      "outputs": [],
      "source": [
        "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jcka-c9_VlZe"
      },
      "outputs": [],
      "source": [
        "trg_text = trg_text.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4_IZQSiVlZe",
        "outputId": "7c9c57f6-8913-4303-f5da-16dbb52f5901"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 6]), torch.Size([1, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "IgAWd7gEVlZe"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "c7_ewO5rVlZe"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUuow44wVlZf",
        "outputId": "a84a9d6f-8092-423b-836c-4316fae9c2c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "output.shape #batch_size, trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n_S_BF1VlZf"
      },
      "source": [
        "Since batch size is 1, we just take off that dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5uVcMsF_VlZf"
      },
      "outputs": [],
      "source": [
        "output = output.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7xOyaFAVlZg",
        "outputId": "cf566a9a-e351-400b-c171-7fbaadb83ceb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqKV4QRVlZg"
      },
      "source": [
        "We shall remove the first token since it's zeroes anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E_NnF7GVlZg",
        "outputId": "64f3ea37-a23c-46d4-e428-35cea8e32d89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 8016])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "output = output[1:]\n",
        "output.shape #trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE9omPNdVlZg"
      },
      "source": [
        "Then we just take the top token with highest probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ImJHvoVOVlZh"
      },
      "outputs": [],
      "source": [
        "output_max = output.argmax(1) #returns max indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL9luNkpVlZh",
        "outputId": "e655822c-662f-4d88-84d7-8f7c29367b1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([35, 17,  5,  3, 17], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "output_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w48ZU9RSVlZh"
      },
      "source": [
        "Get the mapping of the target language"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ],
      "metadata": {
        "id": "IukY4P0pqCy_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2bfH6mmVlZh",
        "outputId": "96087006-2fad-402d-d8c5-27b1bf24b46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "တာ\n",
            "တယ်\n",
            "။\n",
            "<eos>\n",
            "တယ်\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fov4Y7X9VlZh"
      },
      "source": [
        "## 8. Attention\n",
        "\n",
        "Let's display the attentions to understand how the source text links with the generated text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syuon5H6VlZh",
        "outputId": "9acc0f11-919c-48ea-e9db-b268a0af1936"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "attentions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJG9JwA5VlZi"
      },
      "source": [
        "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6o_SVX_VlZi",
        "outputId": "97e261e1-3a5b-4a9c-c8ae-3b1d5b15b6a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "attention = attentions[0, 0, :, :]\n",
        "attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfuK6kkbVlZi",
        "outputId": "33da2db1-e97e-4c09-d6fe-98af6c3e0079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'That', \"'s\", 'all', 'right', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
        "src_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0WbZm7lVlZi",
        "outputId": "4f8b8a4b-3b1d-421c-9acc-12871b2dbb99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', 'တာ', 'တယ်', '။', '<eos>', 'တယ်']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "MpZToAbEVlZi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "    ax.tick_params(labelsize=10)\n",
        "\n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence\n",
        "\n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "ZZ-y3RkYVlZj",
        "outputId": "bd6d35e4-53e3-4cab-b6db-bf3c4b3a1364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-08ff35c238c4>:17: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-73-08ff35c238c4>:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels(y_ticks)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4112 (\\N{MYANMAR LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4140 (\\N{MYANMAR VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4122 (\\N{MYANMAR LETTER YA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4154 (\\N{MYANMAR SIGN ASAT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4171 (\\N{MYANMAR SIGN SECTION}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display_attention(src_tokens, trg_tokens, attention)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "vocab = {\n",
        "    'token_transform': token_transform,\n",
        "    'vocab_transform': vocab_transform,\n",
        "}\n",
        "pickle.dump(vocab, open('models/mtt_additive.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "2MZL103C3vPN"
      },
      "execution_count": 75,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}